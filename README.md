# Max-Text

**Offline Speech-to-Text Desktop App** para Windows e Linux.

Transcreve sua voz para texto em portuguÃªs usando Whisper.cpp, 100% offline.

![Max-Text Screenshot](./docs/screenshot.png)

## âœ¨ Funcionalidades

- ğŸ¤ **Push-to-Talk** - Segure a hotkey para gravar, solte para transcrever
- ğŸ”’ **100% Offline** - Nenhum dado enviado para a nuvem
- âš¡ **RÃ¡pido** - TranscriÃ§Ã£o em tempo real com Whisper.cpp
- ğŸš€ **AceleraÃ§Ã£o GPU** - Suporte a NVIDIA CUDA (6-9x mais rÃ¡pido)
- ğŸ›ï¸ **ConfigurÃ¡vel** - Hotkey, modelo Whisper, microfone
- ğŸŒ **PortuguÃªs** - Otimizado para transcriÃ§Ã£o em portuguÃªs
- ğŸ“‹ **Clipboard** - Texto copiado automaticamente

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Node.js 18+
- npm ou yarn
- Whisper.cpp binÃ¡rio
- Modelo Whisper (ggml-base.bin recomendado)

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/max-text.git
cd max-text

# Instale as dependÃªncias
npm install

# Compile o TypeScript
npm run build

# Execute
npm start
```

### Setup do Whisper

1. **Baixe o whisper.cpp**:
   - Windows: Baixe o release de https://github.com/ggerganov/whisper.cpp/releases
   - Ou compile vocÃª mesmo (veja `resources/README.md`)

2. **Copie o binÃ¡rio**:
   ```bash
   # Windows
   copy whisper.exe resources/bin/

   # Linux
   cp whisper resources/bin/
   chmod +x resources/bin/whisper
   ```

3. **Baixe um modelo**:
   ```bash
   # Modelo base (recomendado)
   curl -L -o ~/.config/max-text/models/ggml-base.bin \
     https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin
   ```

### GPU Acceleration (Opcional)

Se vocÃª tem uma **GPU NVIDIA**, pode habilitar aceleraÃ§Ã£o por GPU para transcriÃ§Ãµes 6-9x mais rÃ¡pidas.

#### Requisitos
- GPU NVIDIA com Compute Capability 5.0+ (GTX 900 series ou mais recente)
- [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) instalado

#### InstalaÃ§Ã£o

1. **Baixe os binÃ¡rios CUDA** do [whisper.cpp releases](https://github.com/ggml-org/whisper.cpp/releases):
   - `whisper-cublas-12.4.0-bin-x64.zip` (recomendado para CUDA 12+)
   - `whisper-cublas-11.8.0-bin-x64.zip` (para CUDA 11.x)

2. **Extraia e copie** para `resources/bin/`:
   ```powershell
   # Arquivos necessÃ¡rios:
   # whisper-cli.exe â†’ renomear para whisper.exe
   # whisper.dll
   # ggml-cuda.dll
   # ggml-base.dll, ggml-cpu.dll, ggml.dll
   # cublas64_12.dll, cublasLt64_12.dll, cudart64_12.dll
   ```

3. **Verifique** que GPU estÃ¡ funcionando:
   ```powershell
   .\resources\bin\whisper.exe 2>&1 | Select-String "CUDA"
   # Deve mostrar: "ggml_cuda_init: found 1 CUDA devices"
   ```

#### Compatibilidade de GPU

| GPU Series | Compute Capability | Suporte |
|------------|-------------------|----------|
| RTX 40xx | 8.9 | âœ… Excelente |
| RTX 30xx | 8.6 | âœ… Excelente |
| RTX 20xx | 7.5 | âœ… Muito Bom |
| GTX 16xx | 7.5 | âœ… Muito Bom |
| GTX 10xx | 6.1 | âœ… Bom |
| GTX 9xx | 5.2 | âš ï¸ Funciona |

> **Nota:** GPU Ã© opcional. Sem GPU, o app usa CPU automaticamente.

## ğŸ“– Uso

1. **Inicie o app** - Ele aparece na system tray
2. **Configure** - Clique com botÃ£o direito no Ã­cone â†’ ConfiguraÃ§Ãµes
3. **Selecione modelo** - Na aba Whisper, escolha o modelo instalado
4. **Use** - Pressione e segure F1 (padrÃ£o) para gravar

### Hotkeys

| Tecla | AÃ§Ã£o |
|-------|------|
| F1 (padrÃ£o) | Push-to-talk |
| ConfigurÃ¡vel | Via Settings |

## âš™ï¸ ConfiguraÃ§Ãµes

- **Hotkey**: Tecla de atalho (F1-F12, Insert, etc.)
- **Modo**: Push-to-Talk ou Toggle
- **Microfone**: SeleÃ§Ã£o de dispositivo de entrada
- **Modelo Whisper**: tiny, base, small, medium, large
- **SaÃ­da**: Copiar para clipboard, salvar histÃ³rico

## ğŸ—ï¸ Arquitetura

```
max-text/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main/        # Electron main process
â”‚   â”œâ”€â”€ preload/     # IPC bridge
â”‚   â””â”€â”€ renderer/    # UI (overlay + settings)
â”œâ”€â”€ core/            # Audio pipeline
â”œâ”€â”€ shared/          # Types and contracts
â””â”€â”€ resources/       # Binaries and assets
```

## ğŸ› ï¸ Desenvolvimento

```bash
# Modo desenvolvimento (com hot reload)
npm run dev

# Build para produÃ§Ã£o
npm run dist

# Apenas compilar TypeScript
npm run build

# Lint
npm run lint
```

## ğŸ“¦ Build

```bash
# Windows
npm run dist -- --win

# Linux
npm run dist -- --linux

# Ambos
npm run dist
```

## ğŸ”§ Troubleshooting

### "Whisper.cpp nÃ£o encontrado"
- Verifique se o binÃ¡rio estÃ¡ em `resources/bin/whisper.exe` (Windows) ou `resources/bin/whisper` (Linux)

### "Modelo nÃ£o encontrado"
- Baixe o modelo de https://huggingface.co/ggerganov/whisper.cpp
- Coloque em `~/.config/max-text/models/` (Linux) ou `%APPDATA%/max-text/models/` (Windows)

### "Hotkey nÃ£o funciona"
- Verifique se outra aplicaÃ§Ã£o nÃ£o estÃ¡ usando a mesma hotkey
- Tente uma tecla diferente nas configuraÃ§Ãµes

### "PermissÃ£o de microfone negada"
- Verifique as configuraÃ§Ãµes de privacidade do sistema
- Permita acesso ao microfone para o Max-Text

## ğŸ“œ LicenÃ§a

MIT License - veja [LICENSE](LICENSE)

## ğŸ™ CrÃ©ditos

- [Whisper](https://github.com/openai/whisper) - OpenAI
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - Georgi Gerganov
- [Electron](https://electronjs.org/)
- [uiohook-napi](https://github.com/phuze/uiohook-napi)
