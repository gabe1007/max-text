# Max-Text

**Offline Speech-to-Text Desktop App** para Windows e Linux.

Transcreve sua voz para texto usando **Whisper.cpp** ou **NVIDIA Parakeet TDT** (via sherpa-onnx), 100% offline. Suporta PortuguÃªs, InglÃªs, FrancÃªs, AlemÃ£o, Italiano e Espanhol.

![Max-Text Screenshot](./docs/screenshot.png)

## âœ¨ Funcionalidades

- ğŸ¤ **Push-to-Talk** - Segure a hotkey para gravar, solte para transcrever
- ğŸ”’ **100% Offline** - Nenhum dado enviado para a nuvem
- âš¡ **RÃ¡pido** - TranscriÃ§Ã£o em tempo real com Whisper.cpp ou Parakeet TDT
- ğŸ”€ **Dual Engine** - Escolha entre Whisper.cpp e NVIDIA Parakeet TDT 0.6B
- ğŸš€ **AceleraÃ§Ã£o GPU** - Suporte a NVIDIA CUDA (6-9x mais rÃ¡pido)
- ğŸ›ï¸ **ConfigurÃ¡vel** - Hotkey, modelo Whisper, microfone
- ğŸŒ **Multi-idioma** - PortuguÃªs, InglÃªs, FrancÃªs, AlemÃ£o, Italiano, Espanhol
- ğŸ“‹ **Clipboard** - Texto copiado automaticamente

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Node.js 18+
- npm ou yarn
- Whisper.cpp binÃ¡rio **e/ou** sherpa-onnx binÃ¡rio (veja setup abaixo)
- Modelo Whisper (ggml-base.bin recomendado) **e/ou** Parakeet TDT

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/max-text.git
cd max-text

# Instale as dependÃªncias
npm install

# Compile o TypeScript e copie os arquivos do renderer
npm run build

# Execute
npm start
```

> **Nota:** `npm run build` compila o TypeScript para `dist/` e copia automaticamente os arquivos do renderer. Em desenvolvimento, use `npm run dev` para hot reload.

### Setup do Whisper

#### OpÃ§Ã£o 1: Script automÃ¡tico (Windows)

```powershell
# Execute no PowerShell dentro da pasta do projeto
.\resources\bin\whisper\download-whisper.ps1
```

> **AtenÃ§Ã£o:** O script baixa a versÃ£o v1.5.4 do whisper.cpp. Para versÃµes mais recentes (que usam `whisper-cli.exe` em vez de `main.exe`), use a OpÃ§Ã£o 2.

#### OpÃ§Ã£o 2: Download manual

1. Baixe o release de https://github.com/ggerganov/whisper.cpp/releases

2. **Copie os arquivos** para `resources/bin/whisper/`:
   ```bash
   # Windows - copie whisper.exe (ou renomeie whisper-cli.exe) e todos os .dll
   copy whisper-cli.exe resources\bin\whisper\whisper.exe
   copy *.dll resources\bin\whisper\

   # Linux
   cp whisper resources/bin/whisper/
   chmod +x resources/bin/whisper/whisper
   ```

3. **Baixe um modelo**:
   ```bash
   # Modelo base (recomendado)
   curl -L -o ~/.config/max-text/models/ggml-base.bin \
     https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin
   ```

### Setup do Parakeet TDT (Alternativa ao Whisper)

O **NVIDIA Parakeet TDT 0.6B V3** Ã© um motor de transcriÃ§Ã£o alternativo com excelente qualidade para PortuguÃªs. Usa o [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx) como runtime.

1. **Baixe o sherpa-onnx**:
   - VÃ¡ para [sherpa-onnx releases](https://github.com/k2-fsa/sherpa-onnx/releases)
   - Windows: `sherpa-onnx-vX.X.X-win-x64-shared-MD-Release.tar.bz2`
   - Linux: `sherpa-onnx-vX.X.X-linux-x64-shared.tar.bz2`

2. **Copie os binÃ¡rios**:
   ```bash
   # Windows - copie sherpa-onnx-offline.exe e todos os .dll
   copy sherpa-onnx-offline.exe resources/bin/sherpa/
   copy *.dll resources/bin/sherpa/

   # Linux - copie o binÃ¡rio e as libs
   cp sherpa-onnx-offline resources/bin/sherpa/
   cp lib/*.so* resources/bin/sherpa/
   chmod +x resources/bin/sherpa/sherpa-onnx-offline
   ```

3. **Baixe o modelo Parakeet TDT** (~640 MB total):
   - Baixe os 4 arquivos de [HuggingFace](https://huggingface.co/csukuangfj/sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8):
     - `encoder.int8.onnx` (622 MB)
     - `decoder.int8.onnx` (11 MB)
     - `joiner.int8.onnx` (6 MB)
     - `tokens.txt` (92 KB)
   - Coloque na pasta de modelos:
     - Windows: `%APPDATA%/max-text/models/parakeet-0.6b/`
     - Linux: `~/.config/max-text/models/parakeet-0.6b/`

4. **Selecione o motor** nas ConfiguraÃ§Ãµes â†’ TranscriÃ§Ã£o â†’ Parakeet

### GPU Acceleration para Whisper (Opcional)

Se vocÃª tem uma **GPU NVIDIA**, pode habilitar aceleraÃ§Ã£o por GPU para Whisper.cpp (6-9x mais rÃ¡pido).
Nas ConfiguraÃ§Ãµes â†’ AceleraÃ§Ã£o, ative **"Usar GPU (CUDA)"**.

> **Nota:** Parakeet TDT 0.6B Ã© leve o suficiente para rodar rÃ¡pido em CPU. GPU nÃ£o traz benefÃ­cio significativo para esse modelo.

#### Requisitos
- GPU NVIDIA com Compute Capability 5.0+ (GTX 900 series ou mais recente)
- [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) instalado

#### InstalaÃ§Ã£o

1. **Baixe os binÃ¡rios CUDA** do [whisper.cpp releases](https://github.com/ggml-org/whisper.cpp/releases):
   - `whisper-cublas-12.4.0-bin-x64.zip` (recomendado para CUDA 12+)
   - `whisper-cublas-11.8.0-bin-x64.zip` (para CUDA 11.x)

2. **Extraia e copie** para `resources/bin/whisper/`:
   ```powershell
   # Arquivos necessÃ¡rios:
   # whisper-cli.exe â†’ renomear para whisper.exe
   # whisper.dll
   # ggml-cuda.dll
   # ggml-base.dll, ggml-cpu.dll, ggml.dll
   # cublas64_12.dll, cublasLt64_12.dll, cudart64_12.dll
   ```

3. **Verifique** que GPU estÃ¡ funcionando:
   ```powershell
   .\resources\bin\whisper\whisper.exe 2>&1 | Select-String "CUDA"
   # Deve mostrar: "ggml_cuda_init: found 1 CUDA devices"
   ```

#### Compatibilidade de GPU

| GPU Series | Compute Capability | Suporte |
|------------|-------------------|----------|
| RTX 40xx | 8.9 | âœ… Excelente |
| RTX 30xx | 8.6 | âœ… Excelente |
| RTX 20xx | 7.5 | âœ… Muito Bom |
| GTX 16xx | 7.5 | âœ… Muito Bom |
| GTX 10xx | 6.1 | âœ… Bom |
| GTX 9xx | 5.2 | âš ï¸ Funciona |

> **Nota:** GPU Ã© opcional. Sem GPU, o app usa CPU automaticamente.

## ğŸ“– Uso

1. **Inicie o app** - Ele aparece na system tray
2. **Configure** - Clique com botÃ£o direito no Ã­cone â†’ ConfiguraÃ§Ãµes
3. **Selecione motor** - Na aba TranscriÃ§Ã£o, escolha Whisper ou Parakeet
4. **Selecione modelo** - Se usar Whisper, escolha o modelo instalado
5. **Use** - Pressione e segure F1 (padrÃ£o) para gravar

### Hotkeys

| Tecla | AÃ§Ã£o |
|-------|------|
| F1 (padrÃ£o) | Push-to-talk |
| ConfigurÃ¡vel | Via Settings |

## âš™ï¸ ConfiguraÃ§Ãµes

- **Hotkey**: Tecla de atalho (F1-F12, Insert, etc.)
- **Modo**: Push-to-Talk ou Toggle
- **Microfone**: SeleÃ§Ã£o de dispositivo de entrada
- **Motor de TranscriÃ§Ã£o**: Whisper ou Parakeet TDT
- **Modelo Whisper**: tiny, base, small, medium, large
- **Idioma**: PortuguÃªs, InglÃªs, FrancÃªs, AlemÃ£o, Italiano, Espanhol
- **GPU**: Ativar/desativar aceleraÃ§Ã£o CUDA
- **SaÃ­da**: Copiar para clipboard, salvar histÃ³rico

## ğŸ—ï¸ Arquitetura

```
max-text/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main/        # Electron main process (config, IPC, Whisper, Sherpa)
â”‚   â”œâ”€â”€ preload/     # IPC bridge
â”‚   â””â”€â”€ renderer/    # UI (overlay + settings)
â”œâ”€â”€ core/            # Audio pipeline
â”œâ”€â”€ shared/          # Types and contracts
â””â”€â”€ resources/
    â”œâ”€â”€ bin/
    â”‚   â”œâ”€â”€ whisper/     # Whisper.cpp binaries + DLLs
    â”‚   â”œâ”€â”€ sherpa/      # sherpa-onnx binaries + DLLs
    â”‚   â””â”€â”€ backup-cpu/  # CPU-only Whisper fallback binaries
    â””â”€â”€ models/          # Whisper .bin models (not tracked by git)
```

## ğŸ› ï¸ Desenvolvimento

```bash
# Modo desenvolvimento (com hot reload)
npm run dev

# Build para produÃ§Ã£o
npm run dist

# Apenas compilar TypeScript
npm run build

# Lint
npm run lint
```

## ğŸ“¦ Build

```bash
# Windows
npm run dist -- --win

# Linux
npm run dist -- --linux

# Ambos
npm run dist
```

## ğŸ”§ Troubleshooting

### "Whisper.cpp nÃ£o encontrado"
- Verifique se o binÃ¡rio estÃ¡ em `resources/bin/whisper/whisper.exe` (Windows) ou `resources/bin/whisper/whisper` (Linux)
- No Windows, certifique-se de que os arquivos `.dll` estÃ£o na mesma pasta (`whisper.dll`, `ggml.dll`, etc.)

### "Modelo nÃ£o encontrado"
- Baixe o modelo de https://huggingface.co/ggerganov/whisper.cpp
- Coloque em `~/.config/max-text/models/` (Linux) ou `%APPDATA%/max-text/models/` (Windows)

### "Hotkey nÃ£o funciona"
- Verifique se outra aplicaÃ§Ã£o nÃ£o estÃ¡ usando a mesma hotkey
- Tente uma tecla diferente nas configuraÃ§Ãµes

### "PermissÃ£o de microfone negada"
- Verifique as configuraÃ§Ãµes de privacidade do sistema
- Permita acesso ao microfone para o Max-Text

### "sherpa-onnx nÃ£o encontrado"
- Verifique se o binÃ¡rio estÃ¡ em `resources/bin/sherpa/sherpa-onnx-offline.exe` (Windows) ou `resources/bin/sherpa/sherpa-onnx-offline` (Linux)
- Certifique-se de copiar todos os arquivos `.dll` (Windows) ou `.so` (Linux) junto

### "Modelo Parakeet nÃ£o encontrado"
- Baixe de https://huggingface.co/csukuangfj/sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8
- Coloque em `~/.config/max-text/models/parakeet-0.6b/` (Linux) ou `%APPDATA%/max-text/models/parakeet-0.6b/` (Windows)
- SÃ£o necessÃ¡rios 4 arquivos: `encoder.int8.onnx`, `decoder.int8.onnx`, `joiner.int8.onnx`, `tokens.txt`

## ğŸ“œ LicenÃ§a

MIT License - veja [LICENSE](LICENSE)

## ğŸ™ CrÃ©ditos

- [Whisper](https://github.com/openai/whisper) - OpenAI
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - Georgi Gerganov
- [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx) - k2-fsa
- [NVIDIA NeMo Parakeet](https://huggingface.co/csukuangfj/sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8) - NVIDIA / csukuangfj
- [Electron](https://electronjs.org/)
- [uiohook-napi](https://github.com/phuze/uiohook-napi)
